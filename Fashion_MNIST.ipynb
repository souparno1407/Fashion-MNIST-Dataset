{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "EL4O6TFqPybg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Managing imports"
      ]
    },
    {
      "metadata": {
        "id": "srS0NLBSU4gI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZLn8Xx3dv81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "metadata": {
        "id": "ZedbOwkmdz7c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mh2ZXzj9d1Vl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Printing the shape of the data"
      ]
    },
    {
      "metadata": {
        "id": "7n1Fuww1d54c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ed4b71c9-4524-4fe8-f7bc-314381c05590"
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nzl-RSvAeGOd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reshaping the data to the form (batch, height, width, channels) form. Here, channels = 1 as the image is in greyscale. Had it been colour, we would have set it to '3'."
      ]
    },
    {
      "metadata": {
        "id": "_Iow8wVCeHLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1). astype('float32')\n",
        "x_test = x_test.reshape(10000, 28, 28, 1). astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9aG4xxiBeJzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculating the mean and standard deviation and then normalizing the pixel values while keeping the mean 0"
      ]
    },
    {
      "metadata": {
        "id": "yAdDF4rBeQuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean = numpy.mean(x_train)\n",
        "std = numpy.std(x_train)\n",
        "x_train = x_train - mean/std\n",
        "x_test = x_test - mean/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQCZX-ZQeSN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since this is a multi-class classification problem with 10 classes, we will be using one-hot encoding for each class. For example, the output for class 0 will be [1, 0, 0, 0, 0, 0, 0, 0, 0,]"
      ]
    },
    {
      "metadata": {
        "id": "kjTaCEU7eX9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number = 10\n",
        "y_train = np_utils.to_categorical(y_train, number)\n",
        "y_test = np_utils.to_categorical(y_test, number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWzFrMlie2DF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we will be defining our model."
      ]
    },
    {
      "metadata": {
        "id": "5jQMu9Bve6uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (5,5), input_shape = (x_train.shape[1], x_train.shape[2], 1), activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Conv2D(64, (4,4), activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation = 'relu'))\n",
        "model.add(Dense(500, activation = 'relu'))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(number, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyFNiFIEfAhk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we will be compiling our model using categorical cross-entropy as a loss function as it is a multi-class classification problem.\n",
        "\n",
        "Adam optimizer is used to ensure that the weights are optimized properly. I have tried other optimizers as well, but Adam gives the best results.\n",
        "\n",
        "Accuracy will be the metric based on which the performance of our neural network will be improved."
      ]
    },
    {
      "metadata": {
        "id": "NWCzSG-DfBdl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_sHosYaf4IN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "jHw0PC-hf4cc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "8bd61400-26c2-4814-c311-6afd0e8be1bf"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 24, 24, 64)        1664      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 9, 9, 64)          65600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 9, 9, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 2, 2, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 2, 2, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 250)               16250     \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 500)               125500    \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1000)              501000    \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 757,720\n",
            "Trainable params: 757,336\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fxPpGu2ZfAbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we will be training our model.\n",
        "\n",
        "The model is going to fit over 50 epochs and is going to update after every 100 images training.\n",
        "\n",
        "The test data is used as the validation dataset."
      ]
    },
    {
      "metadata": {
        "id": "Zsn9MTUXdxmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1723
        },
        "outputId": "926a7b9a-2917-46d7-d2e9-5c41d62097e6"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, batch_size=100)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.4884 - acc: 0.8197 - val_loss: 0.4385 - val_acc: 0.8261\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.3815 - acc: 0.8600 - val_loss: 0.3399 - val_acc: 0.8765\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.3423 - acc: 0.8740 - val_loss: 0.3291 - val_acc: 0.8817\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.3183 - acc: 0.8814 - val_loss: 0.3147 - val_acc: 0.8846\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.3007 - acc: 0.8892 - val_loss: 0.3080 - val_acc: 0.8917\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.2856 - acc: 0.8950 - val_loss: 0.3367 - val_acc: 0.8737\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.2806 - acc: 0.8962 - val_loss: 0.3034 - val_acc: 0.8848\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2689 - acc: 0.9002 - val_loss: 0.3040 - val_acc: 0.8860\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.2634 - acc: 0.9029 - val_loss: 0.2760 - val_acc: 0.9007\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2511 - acc: 0.9072 - val_loss: 0.2792 - val_acc: 0.9012\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2433 - acc: 0.9101 - val_loss: 0.2833 - val_acc: 0.8966\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.2388 - acc: 0.9113 - val_loss: 0.3153 - val_acc: 0.8864\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2312 - acc: 0.9151 - val_loss: 0.2600 - val_acc: 0.9098\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2269 - acc: 0.9168 - val_loss: 0.2624 - val_acc: 0.9070\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2181 - acc: 0.9197 - val_loss: 0.2731 - val_acc: 0.9051\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.2162 - acc: 0.9195 - val_loss: 0.2837 - val_acc: 0.8979\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2129 - acc: 0.9221 - val_loss: 0.2694 - val_acc: 0.9079\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2062 - acc: 0.9237 - val_loss: 0.2792 - val_acc: 0.9052\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.2038 - acc: 0.9254 - val_loss: 0.2726 - val_acc: 0.9059\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.1977 - acc: 0.9272 - val_loss: 0.2586 - val_acc: 0.9101\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1972 - acc: 0.9262 - val_loss: 0.2543 - val_acc: 0.9149\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1905 - acc: 0.9281 - val_loss: 0.2909 - val_acc: 0.9021\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1892 - acc: 0.9299 - val_loss: 0.2498 - val_acc: 0.9160\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1841 - acc: 0.9308 - val_loss: 0.2542 - val_acc: 0.9143\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1824 - acc: 0.9330 - val_loss: 0.2523 - val_acc: 0.9160\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1810 - acc: 0.9325 - val_loss: 0.2607 - val_acc: 0.9135\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1778 - acc: 0.9331 - val_loss: 0.2454 - val_acc: 0.9174\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.1766 - acc: 0.9342 - val_loss: 0.2977 - val_acc: 0.8988\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1748 - acc: 0.9344 - val_loss: 0.2891 - val_acc: 0.9038\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1710 - acc: 0.9366 - val_loss: 0.2469 - val_acc: 0.9164\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1704 - acc: 0.9372 - val_loss: 0.2736 - val_acc: 0.9142\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1667 - acc: 0.9380 - val_loss: 0.2670 - val_acc: 0.9152\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1608 - acc: 0.9411 - val_loss: 0.2796 - val_acc: 0.9090\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1625 - acc: 0.9395 - val_loss: 0.2442 - val_acc: 0.9179\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1608 - acc: 0.9398 - val_loss: 0.2588 - val_acc: 0.9133\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1584 - acc: 0.9419 - val_loss: 0.2595 - val_acc: 0.9186\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.1545 - acc: 0.9424 - val_loss: 0.2512 - val_acc: 0.9197\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1559 - acc: 0.9416 - val_loss: 0.2703 - val_acc: 0.9085\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1499 - acc: 0.9432 - val_loss: 0.2747 - val_acc: 0.9118\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1489 - acc: 0.9443 - val_loss: 0.2590 - val_acc: 0.9158\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1526 - acc: 0.9442 - val_loss: 0.2539 - val_acc: 0.9222\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1477 - acc: 0.9444 - val_loss: 0.2586 - val_acc: 0.9186\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1458 - acc: 0.9453 - val_loss: 0.2543 - val_acc: 0.9207\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1464 - acc: 0.9455 - val_loss: 0.2778 - val_acc: 0.9136\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1408 - acc: 0.9479 - val_loss: 0.2827 - val_acc: 0.9170\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1428 - acc: 0.9475 - val_loss: 0.3476 - val_acc: 0.8937\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.1372 - acc: 0.9491 - val_loss: 0.2569 - val_acc: 0.9195\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1380 - acc: 0.9486 - val_loss: 0.2832 - val_acc: 0.9130\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1381 - acc: 0.9487 - val_loss: 0.2987 - val_acc: 0.9119\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1363 - acc: 0.9495 - val_loss: 0.2613 - val_acc: 0.9220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c73089898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "TmEA1ImcfKQ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Printing the test loss and accuracy"
      ]
    },
    {
      "metadata": {
        "id": "ou_vR3ZPfK4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7d2c43f5-14b8-49a3-c206-eb3d6e07661f"
      },
      "cell_type": "code",
      "source": [
        "metrics = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Metrics(Test loss & Test Accuracy): \")\n",
        "print(metrics[0])\n",
        "print(metrics[1])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metrics(Test loss & Test Accuracy): \n",
            "0.26131384924948214\n",
            "0.922\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}